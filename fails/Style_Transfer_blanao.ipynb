{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Style_Transfer_blanao.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"vvV1Bscox1k1","colab_type":"text"},"cell_type":"markdown","source":["# Transferul Stilului Artistic\n"]},{"metadata":{"id":"iZ-VaWDLx1k3","colab_type":"text"},"cell_type":"markdown","source":["## Introducere\n","\n","În acest laborator vom antrena o rețea convoluțională care primește ca input două imagini (o imagine conținut și o imagine pentru stil) și creează o imagine eterogenă, ce conține contururile imaginii-conținut și culorile și textura imaginii-stil. Acest lucru se realizează prin definirea unor funcții de loss ce pot fi optimizate.\n","\n","Funcția de loss pentru imaginea-conținut încearcă să minimizeze diferența dintre descriptorii care se activează în imaginea-conținut și cei care se activează în imaginea rezultat, la nivelul unuia sau al mai multor layere. Asta are drept rezultat păstrarea contururilor din imaginea conținut în rezultat. \n","\n","Funcția de loss pentru imaginea-stil este puțin mai complicată pentru că încearcă să minimizeze diferența dintre așa-numitele matrice [*Gram*](https://en.wikipedia.org/wiki/Gramian_matrix) pentru imaginea-stil și imaginea finală (la nivelul unuia sau al mai multor layere). Matricea Gram măsoară care descriptori sunt activați simultan într-un anumit layer. Alterând imaginea mixată astfel încât să imite tiparele de activare ale imaginii-stil are drept rezultat transferul culorii și texturii către aceasta.\n","\n","Vom folosi Tensorflow pentru a calcula gradienții acestor funcții de loss. Acest gradient este ulterior folosit pentru a actualiza imaginea mixată, într-un proces iterativ, până când suntem mulțumiți cu rezultatul obținut.\n","\n","![alt text](http://dev.wode.ai/repo/TensorFlow-Tutorials-HvassLabs/images/15_style_transfer_flowchart.svg)\n","\n"]},{"metadata":{"id":"M_undETSx7CK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":59},"outputId":"dfbc3c7d-e743-48fa-9562-347558e454f3","executionInfo":{"status":"ok","timestamp":1527688357975,"user_tz":-180,"elapsed":32441,"user":{"displayName":"MATEI BENEDIC","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115686069875054484949"}}},"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()\n","print(\"OK\")"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-a447e1e6-b59d-4bb7-a51b-0d20a85c2572\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-a447e1e6-b59d-4bb7-a51b-0d20a85c2572\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["OK\n"],"name":"stdout"}]},{"metadata":{"id":"YAgDHKRkSD_G","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":240},"outputId":"396ca8f3-7ed2-46c0-8d7f-cd7ce4e0d8ad","executionInfo":{"status":"ok","timestamp":1527688364666,"user_tz":-180,"elapsed":6619,"user":{"displayName":"MATEI BENEDIC","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115686069875054484949"}}},"cell_type":"code","source":["!pip3 install pretrainedmodels\n","\n","!pip install tqdm\n","!pip install Pillow==4.1.1"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pretrainedmodels in /usr/local/lib/python3.6/dist-packages (0.6.2)\r\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.2.1)\r\n","Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (2.3.2)\r\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.4.0)\r\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (4.1.1)\r\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (1.14.3)\r\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (1.11.0)\r\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision->pretrainedmodels) (0.45.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.23.4)\n","Requirement already satisfied: Pillow==4.1.1 in /usr/local/lib/python3.6/dist-packages (4.1.1)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.1.1) (0.45.1)\n"],"name":"stdout"}]},{"metadata":{"id":"a5zYURlASQmz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import torch\n","import pretrainedmodels.utils as utils\n","import pretrainedmodels\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HL6jqYvHH6fG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"c4ec2117-3a2f-4a75-a6b7-8e5fd1e313da","executionInfo":{"status":"ok","timestamp":1527688366219,"user_tz":-180,"elapsed":653,"user":{"displayName":"MATEI BENEDIC","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115686069875054484949"}}},"cell_type":"code","source":["from tensorflow.python.client import device_lib\n","\n","def get_available_devices():  \n","    local_device_protos = device_lib.list_local_devices()\n","    return [x.name for x in local_device_protos]\n","\n","print(get_available_devices())  "],"execution_count":17,"outputs":[{"output_type":"stream","text":["['/device:CPU:0', '/device:GPU:0']\n"],"name":"stdout"}]},{"metadata":{"id":"Z50ohFPSx1lE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"adef25ef-ba4e-48fb-cd07-f06e886023e9","executionInfo":{"status":"ok","timestamp":1527688367098,"user_tz":-180,"elapsed":651,"user":{"displayName":"MATEI BENEDIC","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115686069875054484949"}}},"cell_type":"code","source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","import PIL.Image\n","from IPython.display import Image, display\n","\n","tf.__version__"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.8.0'"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"FL_ZHLj1SvYW","colab_type":"text"},"cell_type":"markdown","source":["## Modelul inceptionresnetv2\n"]},{"metadata":{"id":"UtJ4dHzox1lb","colab_type":"text"},"cell_type":"markdown","source":["Descarcă modelul VGG-16 dacă nu a fost deja descărcat."]},{"metadata":{"id":"-0SNRAYhSu5B","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#import py/vgg16\n","\n","# vgg16.data_dir = 'vgg16/'\n","#vgg16.maybe_download()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sN9dN6Z7Szra","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#model_name = 'inceptionresnetv2'\n","#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n","#model.eval()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Nv2JqNLBhy1j","colab_type":"text"},"cell_type":"markdown","source":["## Funcții ajutătoare pentru manipularea imaginilor"]},{"metadata":{"id":"CWJndpxkx1ll","colab_type":"text"},"cell_type":"markdown","source":["Această funcție încarcă o imagine; imaginea poate fi redimensionată astfel încât cea mai mare latură să fie `max_size`."]},{"metadata":{"id":"4vdcDcJ3x1lm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":55},"outputId":"28ed50da-e3ca-47c3-c44c-2300873edf28","executionInfo":{"status":"ok","timestamp":1527688370492,"user_tz":-180,"elapsed":573,"user":{"displayName":"MATEI BENEDIC","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115686069875054484949"}}},"cell_type":"code","source":["def load_image(filename, max_size=None):\n","    image = PIL.Image.open(filename)\n","\n","    if max_size is not None:\n","        # Calculează factorul de scalare necesat pentru\n","        # a asigura înălțimea și lățimea maxime, păstrând,\n","        # în același timp, proporțiile dintre acestea.\n","        factor = max_size / np.max(image.size)\n","    \n","        # Redimensionează imaginea\n","        size = np.array(image.size) * factor\n","        size = size.astype(int)\n","        \n","        image = image.resize(size, PIL.Image.LANCZOS)\n","\n","    return np.float32(image)\n","  \n","\"\"\"\n","import torch\n","import pretrainedmodels.utils as utils\n","\n","load_img = utils.LoadImage()\n","\n","# transformations depending on the model\n","# rescale, center crop, normalize, and others (ex: ToBGR, ToRange255)\n","tf_img = utils.TransformImage(model) \n","\n","path_img = 'data/cat.jpg'\n","\n","input_img = load_img(path_img)\n","input_tensor = tf_img(input_img)         # 3x400x225 -> 3x299x299 size may differ\n","input_tensor = input_tensor.unsqueeze(0) # 3x299x299 -> 1x3x299x299\n","input = torch.autograd.Variable(input_tensor,\n","    requires_grad=False)\n","\n","output_logits = model(input) # 1x1000\n","\"\"\""],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nimport torch\\nimport pretrainedmodels.utils as utils\\n\\nload_img = utils.LoadImage()\\n\\n# transformations depending on the model\\n# rescale, center crop, normalize, and others (ex: ToBGR, ToRange255)\\ntf_img = utils.TransformImage(model) \\n\\npath_img = 'data/cat.jpg'\\n\\ninput_img = load_img(path_img)\\ninput_tensor = tf_img(input_img)         # 3x400x225 -> 3x299x299 size may differ\\ninput_tensor = input_tensor.unsqueeze(0) # 3x299x299 -> 1x3x299x299\\ninput = torch.autograd.Variable(input_tensor,\\n    requires_grad=False)\\n\\noutput_logits = model(input) # 1x1000\\n\""]},"metadata":{"tags":[]},"execution_count":21}]},{"metadata":{"id":"aOTMhSsdx1lr","colab_type":"text"},"cell_type":"markdown","source":["Salvează imaginea."]},{"metadata":{"id":"FWIiZyw7x1lu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def save_image(image, filename):\n","    # Asigură că valorile pixelilor sunt în [0, 255]\n","    image = np.clip(image, 0.0, 255.0)\n","    \n","    # Convertește în bytes\n","    image = image.astype(np.uint8)\n","    \n","    # Scrie imaginea\n","    with open(filename, 'wb') as file:\n","        PIL.Image.fromarray(image).save(file, 'jpeg')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Hu_TgwI8x1ly","colab_type":"text"},"cell_type":"markdown","source":["Plotează imaginea."]},{"metadata":{"id":"5hGEtqrLx1lz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def plot_image_big(image):\n","    # Asigură că valorile pixelilor sunt în [0, 255]\n","    image = np.clip(image, 0.0, 255.0)\n","\n","    # Convertește în bytes\n","    image = image.astype(np.uint8)\n","\n","    # Afișează imaginea\n","    display(PIL.Image.fromarray(image))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TTpUChoxx1l4","colab_type":"text"},"cell_type":"markdown","source":["Afișează imaginile-conținut, -mixată și -stil."]},{"metadata":{"id":"TtOczZ9lx1l5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def plot_images(content_image, style_image, mixed_image):\n","    fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n","\n","    fig.subplots_adjust(hspace=0.1, wspace=0.1)\n","\n","    smooth = True\n","    if smooth:\n","        interpolation = 'sinc'\n","    else:\n","        interpolation = 'nearest'\n","\n","    # Afișează imaginea-conținut\n","    ax = axes.flat[0]\n","    ax.imshow(content_image / 255.0, interpolation=interpolation)\n","    ax.set_xlabel(\"Content\")\n","\n","    # Afișează imaginea-mix\n","    ax = axes.flat[1]\n","    ax.imshow(mixed_image / 255.0, interpolation=interpolation)\n","    ax.set_xlabel(\"Mixed\")\n","\n","    # Afișează imaginea-stil\n","    ax = axes.flat[2]\n","    ax.imshow(style_image / 255.0, interpolation=interpolation)\n","    ax.set_xlabel(\"Style\")\n","\n","    for ax in axes.flat:\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","    \n","    plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YNp5ITvlx1l_","colab_type":"text"},"cell_type":"markdown","source":["## Funcțiile de loss\n","\n","Metode ajutătoare pentru definirea funcțiilor de loss."]},{"metadata":{"id":"LRRH64aMx1mA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Calculează MSE între 2 tensori\n","\n","def mean_squared_error(a, b):\n","    return tf.reduce_mean(tf.square(a - b))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h8kyqPP3x1mE","colab_type":"text"},"cell_type":"markdown","source":["Creează funcția de loss pentru imaginea-conținut: MSE între activările de pe un anumit layer al imaginii-conținut și al imaginii-mix. Când această funcție este minimizată, imaginea-mix va avea activările din layerul respectiv asemănătoare cu activările imaginii-conținut. În funcție de layerul selectat, aceasta ar trebui să transfere contururile din imaginea-conținut în imaginea-mix."]},{"metadata":{"id":"sBn5Oyvdx1mF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def create_content_loss(session, model, content_image, layer_ids):\n","    \"\"\"\n","    Creează funcția de loss a imaginii-conținut.\n","    \n","    Parametri:\n","    session: sesiune Tensorflow pentru rularea grafului modelului.\n","    model: modelul (instanță a clasei VGG)\n","    content_image: array numpy reprezentând imaginea-conținut\n","    layer_ids: Listă de id-uri de layere\n","    \"\"\"\n","    \n","    \n","    \n","    input_tensor = tf_img(content_img)\n","    input_tensor = input_tensor.unsqueeze(0)\n","    input = torch.autograd.Variable(input_tensor,\n","    requires_grad=False)\n","    \n","    output_features = model.features(input)\n","    \n","    with model.graph.asdefault():\n","    \n","      loss = mean_squared_error(gram_layer, value_const)\n","    \n","      layer_losses.append(loss)\n","      total_loss = tf.reduce_mean(layer_losses)\n","    \n","    \"\"\"\n","    feed_dict = model.create_feed_dict(image=content_image)\n","\n","    # Obține referințele către tensorii layerelor.\n","    layers = model.get_layer_tensors(layer_ids)\n","\n","    # Calculează rezultatele tensorilor respectivi\n","    values = session.run(layers, feed_dict=feed_dict)\n","\n","    with model.graph.as_default():\n","        # Listă vidă pentru funcțiile de loss\n","        layer_losses = []\n","    \n","        # Pentru fiecare layer\n","        for value, layer in zip(values, layers):\n","            value_const = tf.constant(value)\n","\n","            # Calculează MSE\n","            loss = mean_squared_error(layer, value_const)\n","\n","            # Adaugă la lista de loss-uri\n","            layer_losses.append(loss)\n","\n","        # Calculează media loss-urilor\n","        total_loss = tf.reduce_mean(layer_losses)\n","    \"\"\"\n","     \n","     \n","    return total_loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"30fr9Ahvx1mI","colab_type":"text"},"cell_type":"markdown","source":["Vom aplica e metodă similară pentru layerele de stil, doar că acum dorim să măsurăm care descriptori din layerele de stil se activează simultan pentru imaginea-stil, ca apoi să copiem aceste activări în imaginea-mix.\n","\n","O metodă pentru a realiza asta este să calculăm matricea Gram pentru tensorii layerelor de stil (matricea Gram este o matrice a produsului scalar a vectorilor ce reprezintă activările unui layer).\n","\n","Dacă o valoare din matricea Gram este apropiată de zero, înseamnă că cei doi descriptori din layerul respectiv nu se activează simultan (și vice-versa, dacă o valoare in matricea Gram este mare, înseamnă că cei doi descriptori din layerul respectiv se activează simultan). Astfel, vom încerca să obținem o imagine-mix care reproduce activările din imaginea-stil.\n","\n","Aceasta este funcția ajutătoare pentru calcularea matricei Gram a unui layer într-o rețea convoluțională."]},{"metadata":{"id":"JGiBwyPox1mJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def gram_matrix(tensor):\n","    shape = tensor.get_shape()\n","    \n","    # Obține numărul de canale.\n","    num_channels = int(shape[3])\n","\n","    matrix = tf.reshape(tensor, shape=[-1, num_channels])\n","    \n","    # Calculează matricea Gram ca produs scalar între\n","    # toate combinațiile de 2 canale din tensor\n","    gram = tf.matmul(tf.transpose(matrix), matrix)\n","\n","    return gram                            "],"execution_count":0,"outputs":[]},{"metadata":{"id":"mQaiIrutx1mP","colab_type":"text"},"cell_type":"markdown","source":["Funcția de loss pentru imaginea-stil."]},{"metadata":{"id":"gSU8WC5Mx1mQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def create_style_loss(session, model, style_image, layer_ids):\n","    \"\"\"\n","    Funcția loss pentru imaginea-stil.\n","    \n","    Parametri:\n","    session: sesiune Tensorflow pentru rularea grafului modelului.\n","    model: modelul (instanță a clasei VGG)\n","    style_image: array numpy reprezentând imaginea-stil\n","    layer_ids: Listă de id-uri de layere\n","    \"\"\"\n","\n","    input_tensor = tf_img(style_img)\n","    input_tensor = input_tensor.unsqueeze(0)\n","    input = torch.autograd.Variable(input_tensor,\n","    requires_grad=False)\n","    \n","    output_features = model.features(input)\n","    \n","    gram_val = gram_matrix(output_features)\n","    \n","    values = session.run(gram_val)\n","    \n","    loss = mean_squared_error(gram_layer, value_const)\n","    \n","    layer_losses.append(loss)\n","    total_loss = tf.reduce_mean(layer_losses)\n","    #feed_dict = model.create_feed_dict(image=style_image)\n","\n","    # Obține referințele către tensorii layerelor.\n","    #layers = model.get_layer_tensors(layer_ids)\n","\n","    #with model.graph.as_default():\n","        # Operațiile Tensorflow pentru calculul matricelor Gram\n","        #gram_layers = [gram_matrix(layer) for layer in layers]\n","\n","        # Calculează valorile matricelor Gram\n","        #values = session.run(gram_layers, feed_dict=feed_dict)\n","\n","        # Listă vidă pentru loss-uri\n","        #layer_losses = []\n","    \n","        # Pentru fiecare matrice Gram\n","        #for value, gram_layer in zip(values, gram_layers):\n","            #value_const = tf.constant(value)\n","\n","            # Calculează MSE\n","            #loss = mean_squared_error(gram_layer, value_const)\n","\n","            # Adaugă la lista de loss-uri\n","            #layer_losses.append(loss)\n","\n","        # Calculează media\n","        #total_loss = tf.reduce_mean(layer_losses)\n","        \n","    return total_loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CFxTvzOdx1mW","colab_type":"text"},"cell_type":"markdown","source":["Funcția de loss pentru denoising ([Total Variation Denoising](https://en.wikipedia.org/wiki/Total_variation_denoising)). Aceasta mută imaginea-mix un pixel pe axele *x* și *y*, calculează diferența fața de imaginea originală, pe care o însumează pentru toți pixelii din imagine. Această funcție poate fi folosită pentru a elimina o parte din artefactele din imaginea-mix."]},{"metadata":{"id":"Lva7yKhPx1mX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def create_denoise_loss(model):\n","    loss = tf.reduce_sum(tf.abs(model.input[:,1:,:,:] - model.input[:,:-1,:,:])) + \\\n","           tf.reduce_sum(tf.abs(model.input[:,:,1:,:] - model.input[:,:,:-1,:]))\n","\n","    return loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UkQxtgrQWEqX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"30252ef3-d832-4e70-ce31-71002b3285a2","executionInfo":{"status":"ok","timestamp":1527688795031,"user_tz":-180,"elapsed":1697,"user":{"displayName":"MATEI BENEDIC","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115686069875054484949"}}},"cell_type":"code","source":["!ls"],"execution_count":41,"outputs":[{"output_type":"stream","text":["datalab  style2.jpg  style7.jpg  willy_wonka_new.jpg  willy_wonka_old.jpg\r\n"],"name":"stdout"}]},{"metadata":{"id":"-bbY-oIqx1ma","colab_type":"text"},"cell_type":"markdown","source":["## Algoritmul de Transfer al Stilului\n","\n","Aplică SGD pentru funcțiile de loss definite anterior. Totodată, normalizează funcțiile de loss, pentru a permite ponderarea loss-urilor de conținut și stil."]},{"metadata":{"id":"5gK9guQzx1mb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def style_transfer(content_image, style_image,\n","                   content_layer_ids, style_layer_ids,\n","                   weight_content=1.5, weight_style=10.0,\n","                   weight_denoise=0.3,\n","                   num_iterations=120, step_size=10.0):\n","    \"\"\"\n","    Aplică SGD pentru a minimica loss-urile layerelor de conținut\n","    și de stil; asta ar trebui să rezulte într-o imagine care\n","    păstrează contururile din imaginea-conținut, respectiv culoarea\n","    și textura imaginii-stil.\n","    \n","    Parametri:\n","    content_image: Imaginea-conținut\n","    style_image: Imaginea-stil\n","    content_layer_ids: Lista id-urilor layere-lor de conținut\n","    style_layer_ids: Lista id-urilor layere-lor de stil\n","    weight_content: Ponderea loss-ului de conținut\n","    weight_style: Ponderea loss-ului de stil\n","    weight_denoise: Ponderea loss-ului de denoise\n","    num_iterations: Numărul de iterații\n","    step_size: Dimensiunea unui pas al gradientului în fiecare iterație\n","    \"\"\"\n","\n","    # Creează o instanță a modelului VGG16\n","    #model = vgg16.VGG16()\n","\n","    model_name = 'inceptionresnetv2'\n","    model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n","    \n","    # Creează o sesiune Tensorflow\n","    session = tf.InteractiveSession()\n","\n","    # Printează denumirea layar-elor-conținut\n","    #print(\"Content layers:\")\n","    #print(model.get_layer_names(content_layer_ids))\n","    #print()\n","\n","    # Printează denumirea layer-elor-stil\n","    #print(\"Style layers:\")\n","    #print(model.get_layer_names(style_layer_ids))\n","    #print()\n","\n","    # Creează loss-ul de conținut\n","    loss_content = create_content_loss(session=session,\n","                                       model=model,\n","                                       content_image=content_image,\n","                                       layer_ids=content_layer_ids)\n","\n","    # Creează loss-ul de stil\n","    loss_style = create_style_loss(session=session,\n","                                   model=model,\n","                                   style_image=style_image,\n","                                   layer_ids=style_layer_ids)    \n","\n","    # Creează loss-ul de denoise\n","    loss_denoise = create_denoise_loss(model)\n","\n","    # Variabile pentru ponderile loss-urilor\n","    adj_content = tf.Variable(1e-10, name='adj_content')\n","    adj_style = tf.Variable(1e-10, name='adj_style')\n","    adj_denoise = tf.Variable(1e-10, name='adj_denoise')\n","\n","    session.run([adj_content.initializer,\n","                 adj_style.initializer,\n","                 adj_denoise.initializer])\n","\n","    # Operații Tensorflow pentru actualizarea ponderilor\n","    update_adj_content = adj_content.assign(1.0 / (loss_content + 1e-10))\n","    update_adj_style = adj_style.assign(1.0 / (loss_style + 1e-10))\n","    update_adj_denoise = adj_denoise.assign(1.0 / (loss_denoise + 1e-10))\n","\n","    # Media ponderată a loss-urilor (pe aceasta o vom minimiza)\n","    loss_combined = weight_content * adj_content * loss_content + \\\n","                    weight_style * adj_style * loss_style + \\\n","                    weight_denoise * adj_denoise * loss_denoise\n","\n","    gradient = tf.gradients(loss_combined, model.input)\n","\n","    # Lista tensorilor pe care-i vom actualiza\n","    run_list = [gradient, update_adj_content, update_adj_style, \\\n","                update_adj_denoise]\n","\n","    # Inițializează random imaginea-mix\n","    # mixed_image = np.random.rand(*content_image.shape) + 128\n","    mixed_image = style_image\n","\n","    for i in range(num_iterations):\n","        feed_dict = model.create_feed_dict(image=mixed_image)\n","\n","        # Calculează valoarea gradientului\n","        grad, adj_content_val, adj_style_val, adj_denoise_val \\\n","        = session.run(run_list, feed_dict=feed_dict)\n","\n","        # Reduce dimensionalitatea gradientului\n","        grad = np.squeeze(grad)\n","\n","        step_size_scaled = step_size / (np.std(grad) + 1e-8)\n","\n","        # Actualizează imaginea-mix\n","        mixed_image -= grad * step_size_scaled\n","\n","        # Asigură că valorile pixelilor sunt în [0.0, 255.0]\n","        mixed_image = np.clip(mixed_image, 0.0, 255.0)\n","\n","        print(\". \", end=\"\")\n","\n","        # Afișează status la fiecare 10 iterații\n","        if (i % 10 == 0) or (i == num_iterations - 1):\n","            print()\n","            print(\"Iteration:\", i)\n","\n","            # Afișează ponderi\n","            msg = \"Weight Adj. for Content: {0:.2e}, Style: {1:.2e}, Denoise: {2:.2e}\"\n","            print(msg.format(adj_content_val, adj_style_val, adj_denoise_val))\n","\n","            # Afișează imaginile\n","            plot_images(content_image=content_image,\n","                        style_image=style_image,\n","                        mixed_image=mixed_image)\n","            \n","    print()\n","    print(\"Final image:\")\n","    plot_image_big(mixed_image)\n","\n","    session.close()\n","    \n","    return mixed_image"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7wEOzO8Qx1me","colab_type":"text"},"cell_type":"markdown","source":["## Exemplu"]},{"metadata":{"id":"YpHHojmkdBtu","colab_type":"text"},"cell_type":"markdown","source":["Încarcă imaginea-conținut."]},{"metadata":{"id":"ytk8oDX0UyFf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"75a560a0-05d6-410e-b2d6-7628fd7b4f56","executionInfo":{"status":"ok","timestamp":1527688411878,"user_tz":-180,"elapsed":1548,"user":{"displayName":"MATEI BENEDIC","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115686069875054484949"}}},"cell_type":"code","source":["!ls"],"execution_count":33,"outputs":[{"output_type":"stream","text":["datalab  style2.jpg  style7.jpg  willy_wonka_new.jpg  willy_wonka_old.jpg\r\n"],"name":"stdout"}]},{"metadata":{"id":"NpWhkJFbx1mg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# content_filename = 'images/willy_wonka_old.jpg'\n","content_filename = 'willy_wonka_new.jpg'\n","content_image = load_image(content_filename, max_size=None)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uFQYn7iWx1ml","colab_type":"text"},"cell_type":"markdown","source":["Încarcă imaginea-stil."]},{"metadata":{"id":"xJkjuD23x1mm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# style_filename = 'images/style7.jpg'\n","style_filename = 'style2.jpg'\n","style_image = load_image(style_filename, max_size=300)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tn1DBjcGx1mp","colab_type":"text"},"cell_type":"markdown","source":["Listă de id-uri de layere pentru imaginea-conținut."]},{"metadata":{"id":"wqKrfwpLx1mq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["content_layer_ids = [4]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1VzH2tBix1ms","colab_type":"text"},"cell_type":"markdown","source":["Listă de id-uri de layere pentru imaginea-stil."]},{"metadata":{"id":"bwfnt4hxx1mt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Modelul VGG-16 are 13 layere convoluționale.\n","# Aceasta selectează toate layerele.\n","#style_layer_ids = list(range(13))\n","\n","style_layer_ids = [2, 4, 7, 10, 13]\n","\n","# Puteți selecta și un subset de layere\n","# style_layer_ids = [1, 2, 3, 4]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Uu9s6YYwx1my","colab_type":"text"},"cell_type":"markdown","source":["Aplică transferul de stil"]},{"metadata":{"id":"wJ0VDDs_x1m0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1082},"outputId":"866b74b6-1a2c-4045-c6db-c8116e06a456","executionInfo":{"status":"error","timestamp":1527690277644,"user_tz":-180,"elapsed":2341,"user":{"displayName":"MATEI BENEDIC","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115686069875054484949"}}},"cell_type":"code","source":["%%time\n","img = style_transfer(content_image=content_image,\n","                     style_image=style_image,\n","                     content_layer_ids=content_layer_ids,\n","                     style_layer_ids=style_layer_ids,\n","                     weight_content=1.5,\n","                     weight_style=10.0,\n","                     weight_denoise=0.3,\n","                     num_iterations=60,\n","                     step_size=10.0)"],"execution_count":51,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"],"name":"stderr"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-b967c7cf614b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'img = style_transfer(content_image=content_image,\\n                     style_image=style_image,\\n                     content_layer_ids=content_layer_ids,\\n                     style_layer_ids=style_layer_ids,\\n                     weight_content=1.5,\\n                     weight_style=10.0,\\n                     weight_denoise=0.3,\\n                     num_iterations=60,\\n                     step_size=10.0)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<ipython-input-50-bd91b6403ac4>\u001b[0m in \u001b[0;36mstyle_transfer\u001b[0;34m(content_image, style_image, content_layer_ids, style_layer_ids, weight_content, weight_style, weight_denoise, num_iterations, step_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m                                        \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                                        \u001b[0mcontent_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                                        layer_ids=content_layer_ids)\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Creează loss-ul de stil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-f1b506afa1d0>\u001b[0m in \u001b[0;36mcreate_content_loss\u001b[0;34m(session, model, content_image, layer_ids)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Obține referințele către tensorii layerelor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 532\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'InceptionResNetV2' object has no attribute 'create_feed_dict'"]}]},{"metadata":{"id":"3LoW-hEMx1m9","colab_type":"text"},"cell_type":"markdown","source":["## Exerciții\n","\n","* Încercați să optimizați timp de mai multe iterații (de exemplu 1000, 5000) și cu step-size mai mic. îmbunătățește calitatea?\n","* Modificați ponderile pentru stil, conținut și denoising.\n","* Încercați să începeți optimizarea fie de la imaginea-conținut, fie de la imaginea-stil, sau de la o combinație (medie) a acestora. Puteți, de asemenea, să adăugați și puțin noise.\n","* Încercați să modificați rezoluția imaginilor-conținut și -stil. Puteți folosi argumentul `max_size` al funcției `load_image()` pentru a redimensiona imaginile. Cum afectează rezultatul?\n","* Încercați să folosiți și alte layere din model.\n","* Păstrați parametrii constanți pe toată durata optimizării. Cum afectează rezultatul?\n","* Înlocuiți SGD cu ADAM.\n","* Folosiți alte modele pre-antrenate."]}]}