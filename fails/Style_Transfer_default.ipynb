{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Style_Transfer_default.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"vvV1Bscox1k1","colab_type":"text"},"cell_type":"markdown","source":["# Transferul Stilului Artistic\n"]},{"metadata":{"id":"iZ-VaWDLx1k3","colab_type":"text"},"cell_type":"markdown","source":["## Introducere\n","\n","În acest laborator vom antrena o rețea convoluțională care primește ca input două imagini (o imagine conținut și o imagine pentru stil) și creează o imagine eterogenă, ce conține contururile imaginii-conținut și culorile și textura imaginii-stil. Acest lucru se realizează prin definirea unor funcții de loss ce pot fi optimizate.\n","\n","Funcția de loss pentru imaginea-conținut încearcă să minimizeze diferența dintre descriptorii care se activează în imaginea-conținut și cei care se activează în imaginea rezultat, la nivelul unuia sau al mai multor layere. Asta are drept rezultat păstrarea contururilor din imaginea conținut în rezultat. \n","\n","Funcția de loss pentru imaginea-stil este puțin mai complicată pentru că încearcă să minimizeze diferența dintre așa-numitele matrice [*Gram*](https://en.wikipedia.org/wiki/Gramian_matrix) pentru imaginea-stil și imaginea finală (la nivelul unuia sau al mai multor layere). Matricea Gram măsoară care descriptori sunt activați simultan într-un anumit layer. Alterând imaginea mixată astfel încât să imite tiparele de activare ale imaginii-stil are drept rezultat transferul culorii și texturii către aceasta.\n","\n","Vom folosi Tensorflow pentru a calcula gradienții acestor funcții de loss. Acest gradient este ulterior folosit pentru a actualiza imaginea mixată, într-un proces iterativ, până când suntem mulțumiți cu rezultatul obținut.\n","\n","![alt text](http://dev.wode.ai/repo/TensorFlow-Tutorials-HvassLabs/images/15_style_transfer_flowchart.svg)\n","\n"]},{"metadata":{"id":"M_undETSx7CK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#from google.colab import files\n","#uploaded = files.upload()\n","#print(\"OK\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HL6jqYvHH6fG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"4c4367f6-8d44-48c1-d1e6-8b9d632270dd","executionInfo":{"status":"ok","timestamp":1527694790533,"user_tz":-180,"elapsed":1858,"user":{"displayName":"MATEI BENEDIC","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115686069875054484949"}}},"cell_type":"code","source":["from tensorflow.python.client import device_lib\n","\n","def get_available_devices():  \n","    local_device_protos = device_lib.list_local_devices()\n","    return [x.name for x in local_device_protos]\n","\n","print(get_available_devices())  "],"execution_count":2,"outputs":[{"output_type":"stream","text":["['/device:CPU:0', '/device:GPU:0']\n"],"name":"stdout"}]},{"metadata":{"id":"Z50ohFPSx1lE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"14c728c0-066e-40be-bc00-a18021ad3b99","executionInfo":{"status":"ok","timestamp":1527694791261,"user_tz":-180,"elapsed":672,"user":{"displayName":"MATEI BENEDIC","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115686069875054484949"}}},"cell_type":"code","source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","import PIL.Image\n","from IPython.display import Image, display\n","\n","tf.__version__"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.8.0'"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"3bk8vPmAlTfH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#!rm -r vgg16\n","#!ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D5e2Dl_jx1lR","colab_type":"text"},"cell_type":"markdown","source":["## Modelul VGG-16"]},{"metadata":{"id":"UtJ4dHzox1lb","colab_type":"text"},"cell_type":"markdown","source":["Descarcă modelul VGG-16 dacă nu a fost deja descărcat."]},{"metadata":{"id":"U3VbYDspx1lc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"4fa96001-ed65-48f4-90ad-259a226c742d","executionInfo":{"status":"ok","timestamp":1527694792912,"user_tz":-180,"elapsed":588,"user":{"displayName":"MATEI BENEDIC","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115686069875054484949"}}},"cell_type":"code","source":["import vgg16\n","\n","vgg16.data_dir = 'vgg16/'\n","vgg16.maybe_download()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Downloading VGG16 Model ...\n","Data has apparently already been downloaded and unpacked.\n"],"name":"stdout"}]},{"metadata":{"id":"Nv2JqNLBhy1j","colab_type":"text"},"cell_type":"markdown","source":["## Funcții ajutătoare pentru manipularea imaginilor"]},{"metadata":{"id":"CWJndpxkx1ll","colab_type":"text"},"cell_type":"markdown","source":["Această funcție încarcă o imagine; imaginea poate fi redimensionată astfel încât cea mai mare latură să fie `max_size`."]},{"metadata":{"id":"4vdcDcJ3x1lm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def load_image(filename, max_size=None):\n","    image = PIL.Image.open(filename)\n","\n","    if max_size is not None:\n","        # Calculează factorul de scalare necesat pentru\n","        # a asigura înălțimea și lățimea maxime, păstrând,\n","        # în același timp, proporțiile dintre acestea.\n","        factor = max_size / np.max(image.size)\n","    \n","        # Redimensionează imaginea\n","        size = np.array(image.size) * factor\n","        size = size.astype(int)\n","        \n","        image = image.resize(size, PIL.Image.LANCZOS)\n","\n","    return np.float32(image)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aOTMhSsdx1lr","colab_type":"text"},"cell_type":"markdown","source":["Salvează imaginea."]},{"metadata":{"id":"FWIiZyw7x1lu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def save_image(image, filename):\n","    # Asigură că valorile pixelilor sunt în [0, 255]\n","    image = np.clip(image, 0.0, 255.0)\n","    \n","    # Convertește în bytes\n","    image = image.astype(np.uint8)\n","    \n","    # Scrie imaginea\n","    with open(filename, 'wb') as file:\n","        PIL.Image.fromarray(image).save(file, 'jpeg')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Hu_TgwI8x1ly","colab_type":"text"},"cell_type":"markdown","source":["Plotează imaginea."]},{"metadata":{"id":"5hGEtqrLx1lz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def plot_image_big(image):\n","    # Asigură că valorile pixelilor sunt în [0, 255]\n","    image = np.clip(image, 0.0, 255.0)\n","\n","    # Convertește în bytes\n","    image = image.astype(np.uint8)\n","\n","    # Afișează imaginea\n","    display(PIL.Image.fromarray(image))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TTpUChoxx1l4","colab_type":"text"},"cell_type":"markdown","source":["Afișează imaginile-conținut, -mixată și -stil."]},{"metadata":{"id":"TtOczZ9lx1l5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def plot_images(content_image, style_image, mixed_image):\n","    fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n","\n","    fig.subplots_adjust(hspace=0.1, wspace=0.1)\n","\n","    smooth = True\n","    if smooth:\n","        interpolation = 'sinc'\n","    else:\n","        interpolation = 'nearest'\n","\n","    # Afișează imaginea-conținut\n","    ax = axes.flat[0]\n","    ax.imshow(content_image / 255.0, interpolation=interpolation)\n","    ax.set_xlabel(\"Content\")\n","\n","    # Afișează imaginea-mix\n","    ax = axes.flat[1]\n","    ax.imshow(mixed_image / 255.0, interpolation=interpolation)\n","    ax.set_xlabel(\"Mixed\")\n","\n","    # Afișează imaginea-stil\n","    ax = axes.flat[2]\n","    ax.imshow(style_image / 255.0, interpolation=interpolation)\n","    ax.set_xlabel(\"Style\")\n","\n","    for ax in axes.flat:\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","    \n","    plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YNp5ITvlx1l_","colab_type":"text"},"cell_type":"markdown","source":["## Funcțiile de loss\n","\n","Metode ajutătoare pentru definirea funcțiilor de loss."]},{"metadata":{"id":"LRRH64aMx1mA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Calculează MSE între 2 tensori\n","\n","def mean_squared_error(a, b):\n","    return tf.reduce_mean(tf.square(a - b))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-0Ax3lYGjAsB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def cross_entropy_error(a, b):\n","  return -tf.reduce_mean(b*tf.log(b) + (1 - a)*tf.log(1 - b))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h8kyqPP3x1mE","colab_type":"text"},"cell_type":"markdown","source":["Creează funcția de loss pentru imaginea-conținut: MSE între activările de pe un anumit layer al imaginii-conținut și al imaginii-mix. Când această funcție este minimizată, imaginea-mix va avea activările din layerul respectiv asemănătoare cu activările imaginii-conținut. În funcție de layerul selectat, aceasta ar trebui să transfere contururile din imaginea-conținut în imaginea-mix."]},{"metadata":{"id":"sBn5Oyvdx1mF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def create_content_loss(session, model, content_image, layer_ids):\n","    \"\"\"\n","    Creează funcția de loss a imaginii-conținut.\n","    \n","    Parametri:\n","    session: sesiune Tensorflow pentru rularea grafului modelului.\n","    model: modelul (instanță a clasei VGG)\n","    content_image: array numpy reprezentând imaginea-conținut\n","    layer_ids: Listă de id-uri de layere\n","    \"\"\"\n","    \n","    feed_dict = model.create_feed_dict(image=content_image)\n","\n","    # Obține referințele către tensorii layerelor.\n","    layers = model.get_layer_tensors(layer_ids)\n","\n","    # Calculează rezultatele tensorilor respectivi\n","    values = session.run(layers, feed_dict=feed_dict)\n","\n","    with model.graph.as_default():\n","        # Listă vidă pentru funcțiile de loss\n","        layer_losses = []\n","    \n","        # Pentru fiecare layer\n","        for value, layer in zip(values, layers):\n","            value_const = tf.constant(value)\n","\n","            # Calculează MSE\n","            loss = mean_squared_error(layer, value_const)\n","            #loss = cross_entropy_error(layer, value_const)\n","            # Adaugă la lista de loss-uri\n","            layer_losses.append(loss)\n","\n","        # Calculează media loss-urilor\n","        total_loss = tf.reduce_mean(layer_losses)\n","        \n","    return total_loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"30fr9Ahvx1mI","colab_type":"text"},"cell_type":"markdown","source":["Vom aplica e metodă similară pentru layerele de stil, doar că acum dorim să măsurăm care descriptori din layerele de stil se activează simultan pentru imaginea-stil, ca apoi să copiem aceste activări în imaginea-mix.\n","\n","O metodă pentru a realiza asta este să calculăm matricea Gram pentru tensorii layerelor de stil (matricea Gram este o matrice a produsului scalar a vectorilor ce reprezintă activările unui layer).\n","\n","Dacă o valoare din matricea Gram este apropiată de zero, înseamnă că cei doi descriptori din layerul respectiv nu se activează simultan (și vice-versa, dacă o valoare in matricea Gram este mare, înseamnă că cei doi descriptori din layerul respectiv se activează simultan). Astfel, vom încerca să obținem o imagine-mix care reproduce activările din imaginea-stil.\n","\n","Aceasta este funcția ajutătoare pentru calcularea matricei Gram a unui layer într-o rețea convoluțională."]},{"metadata":{"id":"JGiBwyPox1mJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def gram_matrix(tensor):\n","    shape = tensor.get_shape()\n","    \n","    # Obține numărul de canale.\n","    num_channels = int(shape[3])\n","\n","    matrix = tf.reshape(tensor, shape=[-1, num_channels])\n","    \n","    # Calculează matricea Gram ca produs scalar între\n","    # toate combinațiile de 2 canale din tensor\n","    gram = tf.matmul(tf.transpose(matrix), matrix)\n","\n","    return gram                            "],"execution_count":0,"outputs":[]},{"metadata":{"id":"mQaiIrutx1mP","colab_type":"text"},"cell_type":"markdown","source":["Funcția de loss pentru imaginea-stil."]},{"metadata":{"id":"gSU8WC5Mx1mQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def create_style_loss(session, model, style_image, layer_ids):\n","    \"\"\"\n","    Funcția loss pentru imaginea-stil.\n","    \n","    Parametri:\n","    session: sesiune Tensorflow pentru rularea grafului modelului.\n","    model: modelul (instanță a clasei VGG)\n","    style_image: array numpy reprezentând imaginea-stil\n","    layer_ids: Listă de id-uri de layere\n","    \"\"\"\n","\n","    feed_dict = model.create_feed_dict(image=style_image)\n","\n","    # Obține referințele către tensorii layerelor.\n","    layers = model.get_layer_tensors(layer_ids)\n","\n","    with model.graph.as_default():\n","        # Operațiile Tensorflow pentru calculul matricelor Gram\n","        gram_layers = [gram_matrix(layer) for layer in layers]\n","\n","        # Calculează valorile matricelor Gram\n","        values = session.run(gram_layers, feed_dict=feed_dict)\n","\n","        # Listă vidă pentru loss-uri\n","        layer_losses = []\n","    \n","        # Pentru fiecare matrice Gram\n","        for value, gram_layer in zip(values, gram_layers):\n","            value_const = tf.constant(value)\n","\n","            # Calculează MSE\n","            loss = mean_squared_error(gram_layer, value_const)\n","            #loss = cross_entropy_error(gram_layer, value_const)\n","            # Adaugă la lista de loss-uri\n","            layer_losses.append(loss)\n","\n","        # Calculează media\n","        total_loss = tf.reduce_mean(layer_losses)\n","        \n","    return total_loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CFxTvzOdx1mW","colab_type":"text"},"cell_type":"markdown","source":["Funcția de loss pentru denoising ([Total Variation Denoising](https://en.wikipedia.org/wiki/Total_variation_denoising)). Aceasta mută imaginea-mix un pixel pe axele *x* și *y*, calculează diferența fața de imaginea originală, pe care o însumează pentru toți pixelii din imagine. Această funcție poate fi folosită pentru a elimina o parte din artefactele din imaginea-mix."]},{"metadata":{"id":"Lva7yKhPx1mX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def create_denoise_loss(model):\n","    loss = tf.reduce_sum(tf.abs(model.input[:,1:,:,:] - model.input[:,:-1,:,:])) + \\\n","           tf.reduce_sum(tf.abs(model.input[:,:,1:,:] - model.input[:,:,:-1,:]))\n","\n","    return loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-bbY-oIqx1ma","colab_type":"text"},"cell_type":"markdown","source":["## Algoritmul de Transfer al Stilului\n","\n","Aplică SGD pentru funcțiile de loss definite anterior. Totodată, normalizează funcțiile de loss, pentru a permite ponderarea loss-urilor de conținut și stil."]},{"metadata":{"id":"5gK9guQzx1mb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def style_transfer(content_image, style_image,\n","                   content_layer_ids, style_layer_ids,\n","                   weight_content=1.5, weight_style=10.0,\n","                   weight_denoise=0.3,\n","                   num_iterations=120, step_size=10.0):\n","    \"\"\"\n","    Aplică SGD pentru a minimica loss-urile layerelor de conținut\n","    și de stil; asta ar trebui să rezulte într-o imagine care\n","    păstrează contururile din imaginea-conținut, respectiv culoarea\n","    și textura imaginii-stil.\n","    \n","    Parametri:\n","    content_image: Imaginea-conținut\n","    style_image: Imaginea-stil\n","    content_layer_ids: Lista id-urilor layere-lor de conținut\n","    style_layer_ids: Lista id-urilor layere-lor de stil\n","    weight_content: Ponderea loss-ului de conținut\n","    weight_style: Ponderea loss-ului de stil\n","    weight_denoise: Ponderea loss-ului de denoise\n","    num_iterations: Numărul de iterații\n","    step_size: Dimensiunea unui pas al gradientului în fiecare iterație\n","    \"\"\"\n","    #tf.InteractiveSession.close(self)\n","    # Creează o instanță a modelului VGG16\n","    model = vgg16.VGG16()\n","\n","    # Creează o sesiune Tensorflow\n","    session = tf.InteractiveSession(graph=model.graph)\n","\n","    # Printează denumirea layar-elor-conținut\n","    print(\"Content layers:\")\n","    print(model.get_layer_names(content_layer_ids))\n","    print()\n","\n","    # Printează denumirea layer-elor-stil\n","    print(\"Style layers:\")\n","    print(model.get_layer_names(style_layer_ids))\n","    print()\n","\n","    # Creează loss-ul de conținut\n","    loss_content = create_content_loss(session=session,\n","                                       model=model,\n","                                       content_image=content_image,\n","                                       layer_ids=content_layer_ids)\n","\n","    # Creează loss-ul de stil\n","    loss_style = create_style_loss(session=session,\n","                                   model=model,\n","                                   style_image=style_image,\n","                                   layer_ids=style_layer_ids)    \n","\n","    # Creează loss-ul de denoise\n","    loss_denoise = create_denoise_loss(model)\n","\n","    # Variabile pentru ponderile loss-urilor\n","    adj_content = tf.Variable(1e-10, name='adj_content')\n","    adj_style = tf.Variable(1e-10, name='adj_style')\n","    adj_denoise = tf.Variable(1e-10, name='adj_denoise')\n","\n","    session.run([adj_content.initializer,\n","                 adj_style.initializer,\n","                 adj_denoise.initializer])\n","\n","    # Operații Tensorflow pentru actualizarea ponderilor\n","    update_adj_content = adj_content.assign(1.0 / (loss_content + 1e-10))\n","    update_adj_style = adj_style.assign(1.0 / (loss_style + 1e-10))\n","    update_adj_denoise = adj_denoise.assign(1.0 / (loss_denoise + 1e-10))\n","\n","    # Media ponderată a loss-urilor (pe aceasta o vom minimiza)\n","    loss_combined = weight_content * adj_content * loss_content + \\\n","                    weight_style * adj_style * loss_style + \\\n","                    weight_denoise * adj_denoise * loss_denoise\n","\n","    gradient = tf.gradients(loss_combined, model.input)\n","\n","    # Lista tensorilor pe care-i vom actualiza\n","    run_list = [gradient, update_adj_content, update_adj_style, \\\n","                update_adj_denoise]\n","\n","    # Inițializează random imaginea-mix\n","    # mixed_image = np.random.rand(*content_image.shape) + 128\n","    mixed_image = style_image\n","\n","    for i in range(num_iterations):\n","        feed_dict = model.create_feed_dict(image=mixed_image)\n","\n","        # Calculează valoarea gradientului\n","        grad, adj_content_val, adj_style_val, adj_denoise_val \\\n","        = session.run(run_list, feed_dict=feed_dict)\n","\n","        # Reduce dimensionalitatea gradientului\n","        grad = np.squeeze(grad)\n","\n","        step_size_scaled = step_size / (np.std(grad) + 1e-8)\n","\n","        # Actualizează imaginea-mix\n","        mixed_image -= grad * step_size_scaled\n","\n","        # Asigură că valorile pixelilor sunt în [0.0, 255.0]\n","        mixed_image = np.clip(mixed_image, 0.0, 255.0)\n","\n","        print(\". \", end=\"\")\n","\n","        # Afișează status la fiecare 10 iterații\n","        if (i % 10 == 0) or (i == num_iterations - 1):\n","            print()\n","            print(\"Iteration:\", i)\n","\n","            # Afișează ponderi\n","            msg = \"Weight Adj. for Content: {0:.2e}, Style: {1:.2e}, Denoise: {2:.2e}\"\n","            print(msg.format(adj_content_val, adj_style_val, adj_denoise_val))\n","\n","            # Afișează imaginile\n","            plot_images(content_image=content_image,\n","                        style_image=style_image,\n","                        mixed_image=mixed_image)\n","            \n","    print()\n","    print(\"Final image:\")\n","    plot_image_big(mixed_image)\n","\n","    session.close()\n","    \n","    return mixed_image"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7wEOzO8Qx1me","colab_type":"text"},"cell_type":"markdown","source":["## Exemplu"]},{"metadata":{"id":"YpHHojmkdBtu","colab_type":"text"},"cell_type":"markdown","source":["Încarcă imaginea-conținut."]},{"metadata":{"id":"NpWhkJFbx1mg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# content_filename = 'images/willy_wonka_old.jpg'\n","content_filename = 'willy_wonka_new.jpg'\n","content_image = load_image(content_filename, max_size=None)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uFQYn7iWx1ml","colab_type":"text"},"cell_type":"markdown","source":["Încarcă imaginea-stil."]},{"metadata":{"id":"xJkjuD23x1mm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# style_filename = 'images/style7.jpg'\n","style_filename = 'style3.jpg'\n","style_image = load_image(style_filename, max_size=300)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tn1DBjcGx1mp","colab_type":"text"},"cell_type":"markdown","source":["Listă de id-uri de layere pentru imaginea-conținut."]},{"metadata":{"id":"wqKrfwpLx1mq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["content_layer_ids = [4]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1VzH2tBix1ms","colab_type":"text"},"cell_type":"markdown","source":["Listă de id-uri de layere pentru imaginea-stil."]},{"metadata":{"id":"bwfnt4hxx1mt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Modelul VGG-16 are 13 layere convoluționale.\n","# Aceasta selectează toate layerele.\n","#style_layer_ids = list(range(13))\n","\n","style_layer_ids = [2, 4, 7, 10, 12]\n","\n","# Puteți selecta și un subset de layere\n","# style_layer_ids = [1, 2, 3, 4]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GApUugXKrgjj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Uu9s6YYwx1my","colab_type":"text"},"cell_type":"markdown","source":["Aplică transferul de stil"]},{"metadata":{"id":"wJ0VDDs_x1m0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":3189},"outputId":"3898c674-a153-4b15-ebc9-87038e4cc7c7","executionInfo":{"status":"error","timestamp":1527694810309,"user_tz":-180,"elapsed":5541,"user":{"displayName":"MATEI BENEDIC","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115686069875054484949"}}},"cell_type":"code","source":["%%time\n","img = style_transfer(content_image=content_image,\n","                     style_image=style_image,\n","                     content_layer_ids=content_layer_ids,\n","                     style_layer_ids=style_layer_ids,\n","                     weight_content=1.5,\n","                     weight_style=10.0,\n","                     weight_denoise=0.3,\n","                     num_iterations=60,\n","                     step_size=10.0)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Content layers:\n","['conv3_1/conv3_1']\n","\n","Style layers:\n","['conv2_1/conv2_1', 'conv3_1/conv3_1', 'conv4_1/conv4_1', 'conv5_1/conv5_1', 'conv5_3/conv5_3']\n","\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1,75,43,256] vs. [1,75,75,256]\n\t [[Node: sub_3 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv3_1/conv3_1, Const_6)]]\n\t [[Node: Assign/_51 = _Recv[_start_time=0, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_849_Assign\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-b967c7cf614b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'img = style_transfer(content_image=content_image,\\n                     style_image=style_image,\\n                     content_layer_ids=content_layer_ids,\\n                     style_layer_ids=style_layer_ids,\\n                     weight_content=1.5,\\n                     weight_style=10.0,\\n                     weight_denoise=0.3,\\n                     num_iterations=60,\\n                     step_size=10.0)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<ipython-input-16-8f823f157e19>\u001b[0m in \u001b[0;36mstyle_transfer\u001b[0;34m(content_image, style_image, content_layer_ids, style_layer_ids, weight_content, weight_style, weight_denoise, num_iterations, step_size)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Calculează valoarea gradientului\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_content_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_style_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_denoise_val\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Reduce dimensionalitatea gradientului\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1,75,43,256] vs. [1,75,75,256]\n\t [[Node: sub_3 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv3_1/conv3_1, Const_6)]]\n\t [[Node: Assign/_51 = _Recv[_start_time=0, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_849_Assign\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'sub_3', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-b967c7cf614b>\", line 1, in <module>\n    get_ipython().run_cell_magic('time', '', 'img = style_transfer(content_image=content_image,\\n                     style_image=style_image,\\n                     content_layer_ids=content_layer_ids,\\n                     style_layer_ids=style_layer_ids,\\n                     weight_content=1.5,\\n                     weight_style=10.0,\\n                     weight_denoise=0.3,\\n                     num_iterations=60,\\n                     step_size=10.0)')\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2117, in run_cell_magic\n    result = fn(magic_arg_s, cell)\n  File \"<decorator-gen-60>\", line 2, in time\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\", line 188, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\", line 1193, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 9, in <module>\n  File \"<ipython-input-16-8f823f157e19>\", line 44, in style_transfer\n    layer_ids=content_layer_ids)\n  File \"<ipython-input-12-25859d597bca>\", line 29, in create_content_loss\n    loss = mean_squared_error(layer, value_const)\n  File \"<ipython-input-10-848b9a9bda14>\", line 3, in mean_squared_error\n    return tf.reduce_mean(tf.square(a - b))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\", line 979, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 8009, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [1,75,43,256] vs. [1,75,75,256]\n\t [[Node: sub_3 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv3_1/conv3_1, Const_6)]]\n\t [[Node: Assign/_51 = _Recv[_start_time=0, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_849_Assign\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"]}]},{"metadata":{"id":"KkrseF_VqfGe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"3LoW-hEMx1m9","colab_type":"text"},"cell_type":"markdown","source":["## Exerciții\n","\n","* Încercați să optimizați timp de mai multe iterații (de exemplu 1000, 5000) și cu step-size mai mic. îmbunătățește calitatea?\n","* Modificați ponderile pentru stil, conținut și denoising.\n","* Încercați să începeți optimizarea fie de la imaginea-conținut, fie de la imaginea-stil, sau de la o combinație (medie) a acestora. Puteți, de asemenea, să adăugați și puțin noise.\n","* Încercați să modificați rezoluția imaginilor-conținut și -stil. Puteți folosi argumentul `max_size` al funcției `load_image()` pentru a redimensiona imaginile. Cum afectează rezultatul?\n","* Încercați să folosiți și alte layere din model.\n","* Păstrați parametrii constanți pe toată durata optimizării. Cum afectează rezultatul?\n","* Înlocuiți SGD cu ADAM.\n","* Folosiți alte modele pre-antrenate."]}]}